---
title: 'Embedding texts into latent spaces'
description: 'Testing instructions on Qwen3'
pubDate: 2025-10-02
tags: ['natural-language-processing']
---

For my [masters thesis](https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1323994&dswid=3705) I worked on [Word2Vec](https://arxiv.org/pdf/1301.3781) style models. 
It was in 2019 and [transformers](https://arxiv.org/pdf/1706.03762) were just starting to gain traction.
GPT-2 was revealed and [OpenAI famously said they would not release the model](https://www.youtube.com/watch?v=AJxLtdur5fc) because they were afraid of the potential applications.
It was a different time.

Since then natural language processing (NLP) tools has become more accessible than ever.
NLP has basically become the poster boy for AI. 
There are countless pay-per-token APIs and open source models to download from places like [Hugging Face](https://huggingface.co/models).

Latent spaces have always fascinated me, where complex but regular shapes can be expressed with a few parameters.
My mind was blown then I first learned about autoencoders.
The concept made so much sense to me and it was amazing that one could train a system such a system end-to-end.
And naturally I was intrigued to find out that this can be done for text as well.

Embeddings are normalized vectors $v \in \mathbb{R}^d, \|v\| = 1$.
Word2Vec trains a vocabulary where a word $w$ is translated to a vector $v_w$.
For the latest generation of large language models (LLMs) one typically converts an entire text $s$ into a vector $w_s$.
Document embedding was actually the topic of my thesis, 
I was comparing directly training document embeddings 
([Doc2Vec](https://arxiv.org/pdf/1405.4053), [Doc2VecC](https://arxiv.org/pdf/1707.02377))
versus creating them from, for example, word embeddings as $w_s = \frac{1}{|s|} \sum_{w \in s} v_w$.
It worked alright for most tasks but most of those methods are redudant now.

When training a model to produce embeddings the goal is to make sure that similar texts point in the same direction.
This is the same as saying that the scalar product / cosine distance should be close to 1 for two vectors $v_{s_1} \cdot v_{s_2} = cos(\alpha)$.
For Word2Vec these were also additative so that $v_{king} - v_{man} + v_{woman} \approx v_{queen}$, allowing one to query contextually.
The additative nature comes from how the model is trained. 
LLM embeddings to not allow for this but instead modern embedding models allow queries, which can warp the embedding space.

If I were to work with text analysis today I would download a good, small open source model from Hugging Face.
It is September 2025 as I am writing this and one of the top trending embedding models is a model from Alibaba called [Qwen3-Embedding-0.6B](https://huggingface.co/Qwen/Qwen3-Embedding-0.6B).
It scores well on the [MTEB multilingual leaderboard](https://huggingface.co/spaces/mteb/leaderboard), which is good because as a European you are likely to work with more languages than English.

600 million weights is lightweight enough to run on your personal computer, which I prefer when prototyping.
Using the library `sentence_transformers` one can create embeddings in a jiffy:
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("Qwen/Qwen3-Embedding-0.6B")

sentences = [
    "The weather is lovely today.",
    "I am a cow. Moo!",
    "Fint väder idag."
]
embeddings = model.encode(sentences, prompt = "Treat Swedish and English equally")
similarities = embeddings @ embeddings.T
print(similarities)
```
```
[[1.    0.677 0.898]
 [0.677 1.    0.668]
 [0.898 0.668 1.   ]]
```
If you do not have the model downloaded then model call will do it for you.
One can also download the model artifacts separately and put them in that folder, which is what I did.
This allow you create embeddings offline, which is neat.
I did use the OpenAI embeddings API for a while when it came out (the cost for creating embeddings is low, storing them and quering however...) but not sending potentially sensitive data is preferable.

By the way, removing that prompt "Treat Swedish and English equally" results in the following similarities:
```
[[1.    0.442 0.685]
 [0.442 1.    0.391]
 [0.685 0.391 1.   ]]
```
So warping the embedding space will potentially impact downstream use.
However, its effectiveness remains to be fully understood.
To test this I used Claude to generate some examples of health & safety reports:
```
    1. "En medarbetare föll från en stege på tredje trappsteget när hen skulle byta en glödlampa i taket. Stegen var inte ordentligt säkrad och medarbetaren förlorade balansen. Hen landade på vänster arm och axel. Skadan bedömdes som en stukning i axeln och medarbetaren sökte vård på vårdcentralen. Ingen riskbedömning hade gjorts innan arbetet och stegen saknade stabiliseringsfötter.",
    2. "Under arbete i verkstaden fick en anställd metallspån i ögat när hen svarvade utan att använda skyddsglasögon. Skyddsglasögon fanns tillgängliga men medarbetaren valde att inte använda dem eftersom arbetet bara skulle ta 'någon minut'. Personen behövde akut ögonvård för att avlägsna metallspånet. Arbetsplatsinstruktionen om obligatorisk användning av personlig skyddsutrustning hade inte följts.",
    3. "En lastbilschaufför rapporterade smärta i nedre delen av ryggen efter upprepade lyft av tunga kartonger (ca 25 kg styck) under en hel arbetsdag. Inga lyfthjälpmedel användes trots att sådana fanns tillgängliga på lagret. Chaufören hade inte fått utbildning i ergonomiska lyfttekniker och kände sig pressad av tidsschemat att slutföra leveranserna snabbt. Medicinskt diagnostiserad som muskelspänning i ländryggen.",
    4. "Vid hantering av rengöringsmedel i städförrådet blandades av misstag klorbaserat rengöringsmedel med ammoniak, vilket skapade giftiga ångor. Två städare exponerades och klagade på andningssvårigheter och irritation i svalget. Kemikalierna hade förvarats i omärkta behållare efter att de ursprungliga förpackningarna slängts. Ingen skada krävde sjukhusvård men personalen observerades på plats. Rutiner för kemikaliehantering och märkning hade inte följts.",
```

With the following instruction prompts:
```
Topic: 
"Instruction: Represent this incident report for clustering by the specific type of equipment, tool, or work environment involved (e.g., ladders, machinery, vehicles, chemicals), ignoring the injury and why it happened:"

Root Cause: 
"Instruction: What safety rule or procedure was violated in this incident?"
    
Injury: 
"Instruction: Represent this incident report for clustering by the medical nature and mechanism of injury or potential harm, regardless of activity or cause:"
```

Which yielded the following similarity scores:

| **a** | **b** | **Similarity Topic** | **Similarity Root Cause** | **Similarity Injury** |
|-------|-------|----------------------|---------------------------|-----------------------|
| 1     | 3     | 0.64                 | 0.62                      | 0.68                  |
| 1     | 2     | 0.59                 | 0.62                      | 0.63                  |
| 2     | 3     | 0.54                 | 0.57                      | 0.55                  |
| 3     | 4     | 0.50                 | 0.54                      | 0.54                  |
| 1     | 4     | 0.49                 | 0.51                      | 0.52                  |
| 2     | 4     | 0.49                 | 0.53                      | 0.60                  |

The chemical indicent 4 is the most distinct, only scoring simiarly to the eye-incident on the injury dimension.
This could be because safety goggles are common in chemical handling. 
There definitely are some differences in similarities after conditioning the embeddings on instruction the exact usefulness in this context is hard to gauge.
Injury seems to be differentiate than topic and root causes.

Perhaps for tasks like this it is instead worth classifying or using text generating LLMs to break out the 5 why's or layers in the Swiss cheese model.
Understanding how embeddings can be used to multidimensional concepts still remains to be investigated further.
For now one should mainly use them for "totality" similarity.